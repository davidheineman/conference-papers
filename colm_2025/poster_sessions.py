SESSION_1 = [
    "What is the Visual Cognition Gap between Humans and Multimodal LLMs?",
    "Law of Vision Representation in MLLMs",
    "Interpreting the linear structure of vision-language model embedding spaces",
    "Texture or Semantics? Vision-Language Models Get Lost in Font Recognition",
    "Overcoming Vocabulary Constraints with Pixel-level Fallback",
    "UTF-8 Plumbing: Byte-level Tokenizers Unavoidably Enable LLMs to Generate Ill-formed UTF-8",
    "Jigsaw Puzzles: Splitting Harmful Questions to Jailbreak Large Language Models in Multi-turn Interactions",
    "Can LLMs Handle WebShell Detection? Overcoming Detection Challenges with Behavioral Function-Aware Framework",
    "The Surprising Effectiveness of Membership Inference with Simple N-Gram Coverage",
    "SUV: Scalable Large Language Model Copyright Compliance with Regularized Selective Unlearning",
    "Agents Are All You Need for LLM Unlearning",
    "LM Agents May Fail to Act on Their Own Risk Knowledge",
    "Multi-Agent Systems Execute Arbitrary Malicious Code",
    "LLM-based Multi-Agents System Attack via Continuous Optimization with Discrete Efficient Search",
    "Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games",
    "Breakpoint: Stress-testing systems-level reasoning in LLM agents",
    "Hell or High Water: Evaluating Agentic Recovery from External Failures",
    "Inducing Programmatic Skills for Agentic Tasks",
    "BEARCUBS: A benchmark for computer-using web agents",
    "ADAPT: Actively Discovering and Adapting to Preferences for any Task",
    "Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback",
    "RankAlign: A Ranking View of the Generator-Validator Gap in Large Language Models",
    "Multi-Agent Verification: Scaling Test-Time Compute with Multiple Verifiers",
    "When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning",
    "To Backtrack or Not to Backtrack: When Sequential Search Limits Model Reasoning",
    "Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs",
    "SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild",
    "Enhancing LLM Reasoning with Iterative DPO: A Comprehensive Empirical Investigation",
    "Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate",
    "ReFeed: Multi-dimensional Summarization Refinement with Reflective Reasoning on Feedback",
    "MSRS: Evaluating Multi-Source Retrieval-Augmented Generation",
    "Benchmarking Retrieval-Augmented Generation for Chemistry",
    "Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question Answering via White-Box and Black-Box LLM Collaboration",
    "On Mechanistic Circuits for Extractive Question-Answering",
    "The Dual-Route Model of Induction",
    "Why do LLMs attend to the first token?",
    "Positional Biases Shift as Inputs Approach Context Window Limits",
    "Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs",
    "Assessing Judging Bias in Large Reasoning Models: An Empirical Study",
    "M-Prometheus: A Suite of Open Multilingual LLM Judges",
    "Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks",
    "ThoughtTerminator: Benchmarking, Calibrating, and Mitigating Overthinking in Reasoning Models",
    "LongPerceptualThoughts: Distilling System-2 Reasoning for System-1 Perception",
    "Training Large Language Models to Reason in a Continuous Latent Space",
    "SEAL: Steerable Reasoning Calibration of Large Language Models for Free",
    "Hawkeye: Model Collaboration for Efficient Reasoning",
    "CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing",
    "PredGen: Accelerated Inference of Large Language Models through Input-Time Speculation for Real-Time Speech Interaction",
    "Fast Controlled Generation from Language Models with Adaptive Weighted Rejection Sampling",
    "Self-Steering Language Models",
    "QUDsim: Quantifying Discourse Similarities in LLM-Generated Text",
    "Rhapsody: A Dataset for Highlight Detection in Podcasts",
    "The Devil is in the EOS: Sequence Training for Detailed Image Captioning",
    "Learning Effective Language Representations for Sequential Recommendation via Joint Embedding Predictive Architecture",
    "BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation",
    "EvidenceBench: A Benchmark for Extracting Evidence from Biomedical Papers",
    "$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources",
    "Streaming DiLoCo with overlapping communication",
    "LoRI: Reducing Cross-Task Interference in Multi-Task Low-Rank Adaptation",
    "DFRot: Achieving Outlier-Free and Massive Activation-Free for Rotated LLMs with Refined Rotation",
    "ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models",
    "Layerwise Importance Analysis of Feed-Forward Networks in Transformer-based Language Models",
    "Detecting and Pruning Prominent but Detrimental Neurons in Large Language Models",
    "How Post-Training Reshapes LLMs: A Mechanistic View on Knowledge, Truthfulness, Refusal, and Confidence",
    "Impact of LLM Alignment on Impression Formation in Social Interactions",
    "Values in the Wild: Discovering and Mapping Values in Real-World Language Model Interactions",
    "Beyond Blanket Masking: Examining Granularity for Privacy Protection in Images Captured by Blind and Low Vision Users",
    "How does Watermarking Affect Visual Language Models in Document Understanding?",
    "DualEdit: Dual Editing for Knowledge Updating in Vision-Language Models",
    "SAT: Dynamic Spatial Aptitude Training for Multimodal Language Models",
    "Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses",
    "LawFlow: Collecting and Simulating Lawyersâ€™ Thought Processes on Business Formation Case Studies",
    "A Taxonomy of Transcendence",
    "When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars",
    "Language Models Fail to Introspect About Their Knowledge of Language",
    "Crosslingual Capabilities and Knowledge Barriers in Multilingual Large Language Models",
    "Analyzing Multilingualism in Large Language Models with Sparse Autoencoders",
    "AutoScale: Scale-Aware Data Mixing for Pre-Training LLMs",
    "X-EcoMLA: Upcycling Pre-Trained Attention into MLA for Efficient and Extreme KV Compression",
    "Mixture of Attention Spans: Optimizing LLM Inference Efficiency with Heterogeneous Sliding-Window Lengths",
    "SlowFast-LLaVA-1.5: A Family of Token-Efficient Video Large Language Models for Long-Form Video Understanding",
    "Open-Qwen2VL: Compute-Efficient Pre-Training of Fully-Open Multimodal LLMs on Academic Resources",
]


SESSION_2 = [
    "CLIPPER: Compression enables long-context synthetic data generation",
    "Scaling Laws of Synthetic Data for Language Model",
    "Establishing Task Scaling Laws via Compute-Efficient Model Ladders",
    "Bayesian scaling laws for in-context learning",
    "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B",
    "Gating is Weighting: Understanding Gated Linear Attention through In-context Learning",
    'RWKV-7 "Goose" with Expressive Dynamic State Evolution',
    "One ruler to measure them all: Benchmarking multilingual long-context language models",
    "Zero-shot Benchmarking: A Framework for Flexible and Scalable Automatic Evaluation of Language Models",
    "Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding",
    "SmolVLM: Redefining small and efficient multimodal models",
    "NoWag: A Unified Framework for Shape Preserving Com- pression of Large Language Models",
    "ICQuant: Index Coding enables Low-bit LLM Quantization",
    "Language Model Uncertainty Quantification with Attention Chain",
    "KVSink: Understanding and Enhancing the Preservation of Attention Sinks in KV Cache Quantization for LLMs",
    "SQuat: Subspace-orthogonal KV Cache Quantization",
    "TRELLIS: Learning to Compress Key-Value Memory in Attention Models",
    "Transformers are Efficient Compilers, Provably",
    "Efficient Construction of Model Family through Progressive Training Using Model Expansion",
    "Overfill: Two-Stage Models for Efficient Language Model Decoding",
    "SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths",
    "BlockFFN: Towards End-Side Acceleration-Friendly Mixture-of-Experts with Chunk-Level Activation Sparsity",
    "Exploring Sparse Adapters for Scalable Merging of Parameter Efficient Experts",
    "Pretrained Hybrids with MAD Skills",
    "Base Models Beat Aligned Models at Randomness and Creativity",
    "Limitations of refinement methods for weak to strong generalization",
    "REFA: Reference Free Alignment with Fine-Grained Length Control",
    "Energy-Based Reward Models for Robust Language Model Alignment",
    "Language Model Personalization via Reward Factorization",
    "LoRe: Personalizing LLMs via Low-Rank Reward Modeling",
    "Sharpe Ratio-Guided Active Learning for Preference Optimization in RLHF",
    "More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment",
    "VideoSAVi: Self-Aligned Video Language Models without Human Supervision",
    "Teach Old SAEs New Domain Tricks with Boosting",
    "Layers at Similar Depths Generate Similar Activations Across LLM Architectures",
    "Language models align with brain regions that represent concepts across modalities",
    "Do Language Models Agree with Human Perceptions of Suspense in Stories?",
    "ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models",
    "Multilingual and Multi-Accent Jailbreaking of Audio LLMs",
    "G1yphD3c0de: Towards Safer Language Models on Visually Perturbed Texts",
    "Exposing and Patching the Flaws of Large Language Models in Social Character Simulation",
    "HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Interactive AI Agents",
    "Bootstrapping Visual Assistant Modeling with Situated Interaction Simulation",
    "Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents",
    "An Illusion of Progress? Assessing the Current State of Web Agents",
    "Advancing Language Multi-Agent Learning with Credit Re-Assignment for Interactive Environment Generalization",
    "CONCAP: Seeing Beyond English with Concepts Retrieval-Augmented Captioning",
    "RARe: Retrieval Augmented Retrieval with In-Context Examples",
    "Estimating Optimal Context Length for Hybrid Retrieval-augmented Multi-document Summarization",
    "OpinioRAG: Towards Generating User-Centric Opinion Highlights from Large-scale Online Reviews",
    "Knowledge Graph Retrieval-Augmented Generation via GNN-Guided Prompting",
    "Multi-Agent Retrieval-Augmented Framework for Evidence-Based Counterspeech Against Health Misinformation",
    "The Unlearning Mirage: A Dynamic Framework for Evaluating LLM Unlearning",
    "Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling Opt-Outs",
    "ParaPO: Aligning Language Models to Reduce Verbatim Reproduction of Pre-training Data",
    "Evaluating the Diversity and Quality of LLM Generated Content",
    "Control the Temperature: Selective Sampling for Diverse and High-Quality LLM Outputs",
    "Stop-Think-AutoRegress: Language Modeling with Latent Diffusion Planning",
    "Readability â‰  Learnability: Rethinking the Role of Simplicity in Training Small Language Models",
    "Style over Substance: Distilled Language Models Reason Via Stylistic Replication",
    "Reasoning Models Know When Theyâ€™re Right: Probing Hidden States for Self-Verification",
    "LIMO: Less is More for Reasoning",
    "Exploring the Limit of Outcome Reward for Learning Mathematical Reasoning",
    "Improving LLMsâ€˜ Generalized Reasoning Abilities by Graph Problems",
    "CrossWordBench: Evaluating the Reasoning Capabilities of LLMs and LVLMs with Controllable Puzzle Generation",
    "Finding Flawed Fictions: Evaluating Complex Reasoning in Language Models via Plot Hole Detection",
    "Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation",
    "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?",
    "The Negation Bias in Large Language Models: Investigating bias reflected in linguistic markers",
    "The World According to LLMs: How Geographic Origin Influences LLMs' Entity Deduction Capabilities",
    "MapIQ: Evaluating Multimodal Large Language Models for Map Question Answering",
    "MAC: A Live Benchmark for Multimodal Large Language Models in Scientific Understanding",
    "MLGym: A New Framework and Benchmark for Advancing AI Research Agents",
    "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis",
    "Scoring Verifiers: Evaluating Synthetic Verification for Code and Reasoning",
    "CALLME: Call Graph Augmentation with Large Language Models for Javascript",
    "ALFA: Aligning LLMs to Ask Good Questions A Case Study in Clinical Reasoning",
    "Epistemic Alignment: A Mediating Framework for User-LLM Knowledge Delivery",
    "Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling",
    "Phased Training for LLM-powered Text Retrieval Models Beyond Data Scaling",
    "Reasoning-SQL: Reinforcement Learning with SQL Tailored Partial Rewards for Reasoning-Enhanced Text-to-SQL",
    "Synthetic Data Generation and Multi-Step Reinforcement Learning for Reasoning and Tool Use",
]


SESSION_3 = [
    "IMPersona: Evaluating Individual Level LLM Impersonation",
    "PersonaEval: Are LLM Evaluators Human Enough to Judge Role-Play?",
    "AgentRewardBench: Evaluating Automatic Evaluations of Web Agent Trajectories",
    "RRO: LLM Agent Optimization Through Rising Reward Trajectories",
    "Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning",
    "Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning Code LLMs",
    "AdaptMI: Adaptive Skill-based In-context Math Instructions for Small Language Models",
    "LLMs Are In-Context Bandit Reinforcement Learners",
    "Towards Compute-Optimal Many-Shot In-Context Learning",
    "True Multimodal In-Context Learning Needs Attention to the Visual Context",
    "CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions",
    "Hidden in plain sight: VLMs overlook their visual representations",
    "REM: Evaluating LLM Embodied Spatial Reasoning through Multi-Frame Trajectories",
    "MeMAD: Structured Memory of Debates for Enhanced Multi-Agent Reasoning",
    "A Controlled Study on Long Context Extension and Generalization in LLMs",
    "L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning",
    "Understanding R1-Zero-Like Training: A Critical Perspective",
    "A Critical Look At Tokenwise Reward-Guided Text Generation",
    "Adversarial Training of Reward Models",
    "Insights from the Inverse: Reconstructing LLM Training Goals Through Inverse Reinforcement Learning",
    "Model-Agnostic Policy Explanations with Large Language Models",
    "Vaccine Hesitancy",
    "Exploring Large Language Model Agents for Piloting Social Experiments",
    "AIOS: LLM Agent Operating System",
    "LeakAgent: RL-based Red-teaming Agent for LLM Privacy Leakage",
    "VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation",
    "Breaking the Data Barrier -- Building GUI Agents Through Task Generalization",
    "Plancraft: an evaluation dataset for planning with LLM agents",
    "CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks",
    "UNVEILING: What Makes Linguistics Olympiad Puzzles Tricky for LLMs?",
    "A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths to Reproducibility",
    "From Next-Token to Mathematics: The Learning Dynamics of Mathematical Reasoning in Language Models",
    "MegaMath: Pushing the Limits of Open Math Corpora",
    "Yourbench: Dynamic Evaluation Set Generation with LLMs",
    "Sherkala-Chat: Building a State-of-the-Art LLM for Kazakh in a Moderately Resourced Setting",
    "ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations",
    "AI-Slop to AI-Polish? Aligning Language Models through Edit-Based Writing Rewards and Test-time computation",
    "Modifying Large Language Model Post-Training for Diverse Creative Writing",
    "Ensemble Debiasing Across Class and Sample Levels for Fairer Prompting Accuracy",
    "Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution",
    "Agree to Disagree? A Meta-Evaluation of LLM Misgendering",
    "Both Direct and Indirect Evidence Contribute to Dative Alternation Preferences in Language Models",
    "AIR: A Systematic Analysis of Annotations, Instructions, and Response Pairs in Preference Dataset",
    "Understanding Layer Significance in LLM Alignment",
    "Adaptive Layer-skipping in Pre-trained LLMs",
    "SuperBPE: Space Travel for Language Models",
    "Boundless Byte Pair Encoding: Breaking the Pre-tokenization Barrier",
    "Arctic-Embed 2.0: Multilingual Retrieval Without Compromise",
    "ReasonIR: Training Retrievers for Reasoning Tasks",
    "EnrichIndex: Using LLMs to Enrich Retrieval Indices Offline",
    "Imagine All The Relevance: Scenario-Profiled Indexing with Knowledge Expansion for Dense Retrieval",
    "IterKey: Iterative Keyword Generation with LLMs for Enhanced Retrieval Augmented Generation",
    "Training Plug-and-Play Knowledge Modules with Deep Context Distillation",
    "SlimMoE: Structured Compression of Large MoE Models via Expert Slimming and Distillation",
    "Local Mixtures of Experts: Essentially Free Test-Time Training via Model Merging",
    "Approximating Language Model Training Data from Weights",
    "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models",
    "FineWeb2: One Pipeline to Scale Them All â€” Adapting Pre-Training Data Processing to Every Language",
    "Rethinking Multilingual Continual Pretraining: Data Mixing for Adapting LLMs Across Languages and Resources",
    "Humans overrely on overconfident language models, across languages",
    "Beyond the Reported Cutoff: Where Large Language Models Fall Short on Financial Knowledge",
    "(Im)possibility of Automated Hallucination Detection in Large Language Models",
    "Out-of-Distribution Detection using Synthetic Data Generation",
    "Teaching Models to Understand (but not Generate) High-risk Data",
    "Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning",
    "Understanding and Improving Noisy Embedding Techniques in Instruction Finetuning",
    "SAEs Can Improve Unlearning: Dynamic Sparse Autoencoder Guardrails for Precision Unlearning in LLMs",
    "Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality",
    "Elucidating the Design Space of Decay in Linear Attention",
    "Multi-Token Attention",
    "Rethinking Associative Memory Mechanism in Induction Head",
    "Plato: Plan to Efficient Decode for Large Language Model Inference",
    "SentenceKV: Efficient LLM Inference via Sentence-Level Semantic KV Caching",
    "Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning Models",
    "OpenCodeReasoning: Advancing Data Distillation for Competitive Coding",
    "RepoST: Scalable Repository-Level Coding Environment Construction with Sandbox Testing",
    "R2E-Gym: Procedural Environment Generation and Hybrid Verifiers for Scaling Open-Weights SWE Agents",
    "DoomArena: A framework for Testing AI Agents Against Evolving Security Threats",
    "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees",
    "Rerouting LLM Routers",
    "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning",
    "The Blessing and Curse of Dimensionality in Safety Alignment",
    """Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought'' Control""",
    "Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups",
    "News is More than a Collection of Facts: Moral Frame Preserving News Summarization",
]

SESSION_4 = [
    "VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information",
    "Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in Vision-Language Models",
    "Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation",
    "Post-training for Efficient Communication via Convention Formation",
    "Reinforcement Learning Enhanced Full-Duplex Spoken Dialogue Language Models for Conversational Interactions",
    "Scaling Analysis of Interleaved Speech-Text Language Models",
    "EllieSQL: Cost-Efficient Text-to-SQL with Complexity-Aware Routing",
    "Improving Table Understanding with LLMs and Entity-Oriented Search",
    "Understanding the Uncertainty of LLM Explanations: A Perspective Based on Reasoning Topology",
    "Noiser: Bounded Input Perturbations for Attributing Large Language Models",
    "You Cannot Feed Two Birds with One Score: the Accuracy-Naturalness Tradeoff in Translation",
    "Backdoor Attacks on Dense Retrieval via Public and Unintentional Triggers",
    "JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model",
    "Cutting the Root of Hallucination: Structural Trimming for Vulnerability Mitigation in Code LLMs",
    "FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios",
    "Inside-Out: Hidden Factual Knowledge in LLMs",
    "Discovering Knowledge Deficiencies of Language Models on Massive Knowledge Base",
    "EvalTree: Profiling Language Model Weaknesses via Hierarchical Capability Trees",
    "EvalAgents: Discovering Implicit Evaluation Criteria from the Web",
    "DÃ©jÃ  Vu: Multilingual LLM Evaluation through the Lens of Machine Translation Evaluation",
    "LLMs as Research Tools: A Large Scale Survey of Researchersâ€™ Usage and Perceptions",
    "Deep Binding of Language Model Virtual Personas: a Study on Approximating Political Partisan Misperceptions",
    "HIPPO-VIDEO : Simulating Watch Histories with Large Language Models for History-Driven Video Highlighting",
    "MuSeD: A Multimodal Spanish Dataset for Sexism Detection in Social Media Videos",
    "MixAssist: An Audio-Language Dataset for Co-Creative AI Assistance in Music Mixing",
    "CoLa: Learning to Interactively Collaborate with Large Language Models",
    "Weak-for-Strong: Training Weak Meta-Agent to Harness Strong Executors",
    "Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments",
    "Adaptive Computation Pruning for the Forgetting Transformer",
    "RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale",
    "Single-Pass Document Scanning for Question Answering",
    "Stuffed Mamba: Oversized States Lead to the Inability to Forget",
    "Overflow Prevention Enhances Long-Context Recurrent LLMs",
    "Resona: Improving Context Copying in Linear Recurrence Models with Retrieval",
    "Impact-driven Context Filtering For Cross-file Code Completion",
    "CASCADE Your Datasets for Cross-Mode Knowledge Retrieval of Language Models",
    "NoveltyBench: Evaluating Creativity and Diversity in Language Models",
    "The Zero Body Problem: Probing LLM Use of Sensory Language",
    "Probing Syntax in Large Language Models: Successes and Remaining Challenges",
    "Truth-value judgment in language models: â€˜truth directionsâ€™ are context sensitive",
    "Do Biased Models Have Biased Thoughts?",
    "On the Effectiveness and Generalization of Race Representations for Debiasing High-Stakes Decisions",
    "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective",
    "Always Tell Me The Odds: Fine-grained Conditional Probability Estimation",
    "FineMedLM-o1: Enhancing Medical Knowledge Reasoning Ability of LLM from Supervised Fine-Tuning to Test-Time Training",
    "D3: A Dataset for Training Code LMs to Act Diff-by-Diff",
    "Unifying Autoregressive and Diffusion-Based Sequence Generation",
    "Tulu 3: Pushing Frontiers in Open Language Model Post-Training",
    "The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong Gains",
    "Data-Centric Human Preference with Rationales for Direct Preference Alignment",
    "Sample Efficient Preference Alignment in LLMs via Active Exploration",
    "A Survey on Personalized and Pluralistic Preference Alignment in Large Language Models",
    "CUPID: Evaluating Personalized and Contextualized Alignment of LLMs from Interactions",
    "SPIN-Bench: How Well Do LLMs Plan Strategically and Reason Socially?",
    "Do Large Language Models Have a Planning Theory of Mind? Evidence from MindGames: a Multi-Step Persuasion Task",
    "Hypothesis-Driven Theory-of-Mind Reasoning for Large Language Models",
    "Have Large Language Models Learned to Reason? A Characterization via 3-SAT",
    "Reverse-engineering NLI: A study of the meta-inferential properties of Natural Language Inference",
    "Resource-efficient Inference with Foundation Model Programs",
    "MÂ²IV: Towards Efficient and Fine-grained Multimodal In-Context Learning via Representation Engineering",
    "How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding",
    "Context-Adaptive Multi-Prompt Embedding with Large Language Models for Vision-Language Alignment",
    "Shared Global and Local Geometry of Language Model Embeddings",
    "Steering Large Language Model Activations in Sparse Spaces",
    "Spike No More: Stabilizing the Pre-training of Large Language Models",
    "Hyperparameter Loss Surfaces Are Simple Near their Optima",
    "HyperINF: Unleashing the HyperPower of Schulz's Method for Data Influence Estimation",
    "Improving Fisher Information Estimation and Efficiency for LoRA-based LLM Unlearning",
    "Not All Data Are Unlearned Equally",
    "Rethinking Safety in LLM Fine-tuning: An Optimization Perspective",
    "FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning",
    "When Splitting Makes Stronger: A Theoretical and Empirical Analysis of Divide-and-Conquer Prompting in LLMs",
    "Effective Length Extrapolation via Dimension-Wise Positional Embeddings Manipulation",
    "LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K",
    "LongProc: Benchmarking Long-Context Language Models on Long Procedural Generation",
    "Learning to Reason for Long-Form Story Generation",
    "GenerationPrograms: Fine-grained Attribution with Executable Programs",
    "Learning to Generate Unit Tests for Automated Debugging",
    "Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving",
    "FormaRL: Enhancing Autoformalization with no Labeled Data",
    "Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers",
    "Rank1: Test-Time Compute for Reranking in Information Retrieval",
    "BigCharts-R1: Enhanced Chart Reasoning with Visual Reinforcement Finetuning",
]

SESSION_5 = [
    "Implicit In-Context Learning: Evidence from Artificial Language Experiments",
    "Task Vectors in In-Context Learning: Emergence, Formation, and Benefits",
    "In-Context Occamâ€™s Razor: How Transformers Prefer Simpler Hypotheses on the Fly",
    "Task-Circuit Quantization: Leveraging Knowledge Localization and Interpretability for Compression",
    "PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling",
    "E$^2$-RAG: Towards Editable Efficient RAG by Editing Compressed KV Caches",
    "$\mu$KE: Matryoshka Unstructured Knowledge Editing of Large Language Models",
    "LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks",
    "LLM Unlearning Without an Expert Curated Dataset",
    "Short-PHD: Detecting Short LLM-generated Text with Topological Data Analysis After Off-topic Content Insertion",
    "One-shot Optimized Steering Vectors Mediate Safety-relevant Behaviors in LLMs",
    "LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models",
    "PolyGuard: A Multilingual Safety Moderation Tool for 17 Languages",
    "Customize Multi-modal RAI Guardrails with Precedent-based predictions",
    "Mitigating Modal Imbalance in Multimodal Reasoning",
    "SEAM: Semantically Equivalent Across Modalities Benchmark for Vision-Language Models",
    "Visual Representations inside the Language Model",
    "Traceable and Explainable Multimodal Large Language Models: An Information-Theoretic View",
    "Efficient Self-Improvement in Multimodal Large Language Models: A Model-Level Judge-Free Approach",
    "Self-Evolving Critique Abilities in Large Language Models",
    "Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education",
    "Building Instruction-Tuning Datasets from Human-Written Instructions with Open-Weight Large Language Models",
    "SmolLM2: When Smol Goes Big â€” Data-Centric Training of a Fully Open Small Language Model",
    "2 OLMo 2 Furious (COLMâ€™s Version)",
    "Scalable Zeroth-Order Fine-Tuning for Extremely Large Language Models with Limited GPU Memory",
    "Privately Learning from Graphs with Applications in Fine-tuning Large Language Models",
    "URANIA: Differentially Private Insights into AI Use",
    "Towards User-level Private Reinforcement Learning with Human Feedback",
    "Extragradient Preference Optimization (EGPO): Beyond Last-Iterate Convergence for Nash Learning from Human Feedback",
    "In-context Ranking Preference Optimization",
    "VaPR - Vision-language Preference alignment for Reasoning",
    "PrefPalette: Personalized Preference Modeling with Latent Attributes",
    "Know Me, Respond to Me: Benchmarking LLMs for Dynamic User Profiling and Personalized Responses at Scale",
    "Probing then Editing Response Personality of Large Language Models",
    """Can LLM "Self-report"?: Evaluating the Validity of Self-report Scales in Measuring Personality Design in LLM-based Chatbots""",
    "From Queries to Criteria: Understanding How Astronomers Evaluate LLMs",
    "Brains vs. Bytes: Evaluating LLM Proficiency in Olympiad Mathematics",
    "Evaluating Large Language Models as Expert Annotators",
    "Verifying the Verifiers: Unveiling Pitfalls and Potentials in Fact Verifiers",
    "Partial Perspectives: How LLMs Handle Logically Inconsistent Knowledge in Reasoning Tasks",
    "Prompt-Reverse Inconsistency: LLM Self-Inconsistency Beyond Generative Randomness and Prompt Paraphrasing",
    "Missing Premise exacerbates Overthinking: Are Reasoning Models losing Critical Thinking Skill?",
    "Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models",
    "X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents",
    "SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression",
    "CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation",
    "Correctness-Guaranteed Code Generation via Constrained Decoding",
    "SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers",
    "LongCodeBench: Evaluating Coding LLMs at 1M Context Windows",
    "CodeXEmbed: A Generalist Embedding Model Family for Multilingual and Multi-task Code Retrieval",
    "DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning",
    "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning",
    "Echo Chamber: RL Post-training Amplifies Behaviors Learned in Pretraining",
    "MALT: Improving Reasoning with Multi-Agent LLM Training",
    "Boosting LLM Reasoning via Spontaneous Self-Correction",
    "Speculative Thinking: Enhancing Small-Model Reasoning with Large Model Guidance at Inference Time",
    "Learning Adaptive Parallel Reasoning with Language Models",
    "Weight ensembling improves reasoning in language models",
    "Can Test-Time Scaling Improve World Foundation Model?",
    "MS-SSM: A Multi-Scale State Space Model for Efficient Sequence Modeling",
    "StagFormer: Time Staggering Decoder only Transformers",
    "DEL: Context-Aware Dynamic Exit Layer for Efficient Self-Speculative Decoding",
    "AdaptiVocab: Enhancing LLM Efficiency in Focused Domains through Lightweight Vocabulary Adaptation",
    "Cascade Reward Sampling for Efficient Decoding-Time Alignment",
    "Self-Rewarding PPO: Aligning Large Language Models with Demonstrations Only",
    "Efficient Process Reward Model Training via Active Learning",
    "Scaling Web Agent Training through Automatic Data Generation and Fine-grained Evaluation",
    "DynaSaur: Large Language Agents Beyond Predefined Actions",
    "Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning",
    "Donâ€™t lie to your friends: Learning what you know from collaborative self-play",
    "Retrieval-Augmented Generation with Conflicting Evidence",
    "Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models",
    "Pairwise or Pointwise? Evaluating Feedback Protocols for Bias in LLM-Based Evaluation",
    "Fluid Language Model Benchmarking",
    "QAPyramid: Fine-grained Evaluation of Content Selection for Text Summarization",
    "Do LLMs Understand Your Translations? Evaluating Paragraph-level MT with Question Answering",
    "Evaluating LLMs on Chinese Idiom Translation",
    "Multilingual Contextualization of Large Language Models for Document-Level Machine Translation",
    "EuroBERT: Scaling Multilingual Encoders for European Languages",
    "SpectR: Dynamically Composing LM Experts with Spectral Routing",
    "C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization for Test-Time Expert Re-Mixing",
    "Can a Crow Hatch a Falcon? Lineage Matters in Predicting Large Language Model Performance",
    "Register Always Matters: Analysis of LLM Pretraining Data Through the Lens of Language Variation",
    "Supposedly Equivalent Facts That Arenâ€™t? Entity Frequency in Pre-training Induces Asymmetry in LLMs",
    "How do language models learn facts? Dynamics, curricula and hallucinations",
    "Hardware-Efficient Attention for Fast Decoding",
]
